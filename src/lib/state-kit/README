This is a placeholder directory for a planned state
management toolkit based upon the "Adaptive Functional
Programming" paper:

     Adaptive Functional Programming
     Umut A. Acar, Guy E. Blelloch, Robert Harper (all CMU)
     2002, 13p
     http://pag.csail.mit.edu/reading-group/acar02adaptive.pdf


MOTIVATION
----------

The motivation here is that single-threaded UI designs
suck, as does any sort of large-scale programming based
upon the single-thread paradigm:  Life turns into an
endless juggling act of trying to rotate that single
program counter through all the places it is needed --
the very worst sort of distributed scheduling!  :)

But simple thread-and-queue toolkits like CML aren't
a great improvement:  A rats-nest of threads and queues
is if anything worse than the rats-nest GOTO logic of
the bad old days.

The solution to GOTO rats-nests was programming using
less general control structures that compose nicely to
give predictable properties.  Like termination.

The solution to threads-and-queues ratnests is likewise
going to involve using less general constructs which
compose nidely to give predictable properties.  Like
lack of deadlock.

OVERVIEW
--------


       +-----------+      +-----------+
       |Input side |      |Input side |
       |Latch A    |      |Latch B    |
       |Output side|      |Output side|
       +-----------+      +-----------+
         |     \            /   |
         |      \          /    |
         |       \        /     |
         |        \      /      | 
         |         \    /       |
         |          \  /        |
         |           \/         |
         |           /\         | 
         |          /  \        |
         |         /    \       |
         |        /      \      |
         |       /        \     |
         |      /          \    |
         V     V            V   V 
      .................  ................. 
      . Logic block A .  . Logic block B .
      .................  .................
         |                      |
         |                      |
         V                      V 
       +-----------+      +-----------+
       |Input side |      |Input side |
       |Latch C    |      |Latch D    |
       |Output side|      |Output side|
       +-----------+      +-----------+

As a quick and naive overview of modern VLSI circuit
design, circuit elements are divided into latches and
logic blocks:

    o A latch holds state between and during clock cycles.
      It does no interesting computations of its own.

    o A logic block combines information from various
      latches into interesting new values, which it feeds
      to other latches.  A logic block cannot remember
      state between clock cycles.  Signals ripple through
      a logic block, rather than being stored in it.

The life cycle of such a circuit looks like so:

 1) At the start of a clock cycle, each latch copies
    the information on its input side to its output
    side, and latches it there.  The latch output side
    is then fixed, while the input side is floating,
    ready to read new input.

 2) The output latch values ripple through the logic
    blocks, eventually reaching the input sides of
    of the latches.  (The worst-case time needed for
    information to ripple through all logic blocks
    determines the minimum length of a clock cycle,
    and thus how fast the circuit can run.)

 3) The latches lock onto their input values, and
    stop driving their output sides.

Repeat a billion times a second or so. :)

This latch-vs-logic-block dichotomy is part of the
discipline which allows electrical engineers to
tame the complexity of billion-transistor chips
and spin chips that work on first silicon.



The state-kit applies a somewhat similar discipline
to software design:  We divide our software into
latches and nodes:

    o All the changable state of the system is
      stored in latches, which may hold arbitrary
      Mythryl values, but which do no interesting
      computations of their own.

    o All computations are done by code nodes:
      pure-functional Mythryl functions which
      read values out of latches, compute
      interesting new values based upon those
      values, and write the results into other
      latches.

Unlike the electrical circuit, we do not re-evaluate
every code node on every cycle.  (The electical
engineers can run all their logic blocks in parallel.
We lack that luxury!)  Rather, we evaluate
only those whose inputs have changed.  This gives
the computation a parallel, dataflow character
much like a Petri net.  A central scheduling algorith
decides which code node to evaluate first, based on
analysis of a global dependency graph recording the
relationships of all latches and code nodes.

This scheduling algorithm is adapted from that
descriped in the above-mentioned Adaptive
Functional Programming paper.

The "Adaptive Functional Programming" mechanism was
proposed as a general way of converting non-incremental
algorithms (such as classical convex-hull) into
incremental versions which can efficiently convert
small changes into the input dataset into small updates
to the output dataset (as opposed to having to recompute
from the scratch).

But we can adapt the same mechanism to provide a general
controllable state management kit:  The state of our GUI
program is kept in latches (AFP "modifiables"), which
are connected by AFP code nodes, scheduled for execution
per the AFP algorithm.

This provides a number of advantages:

  o Efficient "natural order" update of outputs in
    response to inputs.

  o Lock-free by design:  The AFP algorithm can be
    designed never to run at the same time two code
    nodes with common output latches (&tc).  (Or else
    it can transparently handle any needed locking.)

  o Deadlock-free by design:  The AFP algorithm builds
    a global dependency graph which may easily be
    verified to be acyclic, and the AFP scheduling
    algorith provides a central place to manage
    threadkitramming and multiprocessing issues.
    (The CML model, as such, provides no natural
    central place with a global view of program
    topology.)

  o Threadkitramming (and eventually multiprocessing)
    without tears -- allowing for example GUI interfaces
    that stay responsive even while major computations
    are ongoing in the background.

  o A central switch at which GUI processing can be
    turned off, for example in a GUI builder during
    rewiring.  (CML per se conspicuously lacks this.)

    As a practical matter, a large system is likely
    to have multiple AFP-managed code nets, which
    can be independently de/activated.  In fact,
    we're likely to wind up with hierarchies of them.

    But we should be able to start with just one,
    and expand easily as needed.

[I'd anticipate that large-scale re-usable software
components are likely to be predominantly modules 
with AFP-style dataflow latche interfaces, rather than
function-call interfaces.  But that's getting a bit
ahead of the game... ]

It is instructive to compare the AFP model with other
similar models such as event driven programming and
reactive programming.

One important insight which emerges is that some
code nodes will be history-sensitive:  Their output
latch state(s) will depend not just on the current
states of their input latches, but on the -history- of
states of those lateches.  E.g., the contents of a
text buffer depends not just on the last keystroke typed,
but on the history of all keystrokes typed during the
session.

(One could get around this by requiring
that the complete keystroke history be explicitly
maintained on input latches, but this approach is
liable to prove unnatural and prohibitively expensive
in many practical cases -- a router, for example,
cannot afford to store every packet passing through it.)

This can be handled by having code nodes notify
AFP that they are history-sensitive when registering
an input latch and changing the AFP scheduling algorithm
to ensure that such nodes are executed exactly
once for each changed input latch value.

We may similarly need to make some provisions for
distinguishing offline, soft-realtime and hard-realtime
computations.  These should be fairly easy to fold in:
Given an acyclic dependency graph and some way
to measure, calculate or declare the worst-time
execution behavior of individual code nodes, it should
be fairly simple for the AFP scheduler to compute
the feasibility of declared realtime processing
constraints, and to adopt a schedule respecting them,
at least for a reasonable variety of practically useful
cases.  (I'm sure one can concoct NP-hard scheduling
problems without much effort. I'm hoping and expecting
that a wide variety of useful programs can be handled
without entering such waters.)

For a first cut, I expect we'll just distinguish
'high' and 'low' priority nodes, and favor the former
with high probability whenver both are eligible to run.
(Completely starving 'low' priority nodes is unlikely
to be wise.)  But it is good to have a roadmap leading
smoothly to more sophisticated fare.

NB: When implementing such stuff comes up, it would
be worth checking out what the Timber (nee' O'Haskell)
folks in Oregon have learned in the meantime about
functional realtime programming.

