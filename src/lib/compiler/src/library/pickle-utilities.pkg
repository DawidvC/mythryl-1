#
# Pickle utilities.
#
#
#                       OVERVIEW
#                       ========
#
# This module contains the core functionality used for 'pickling',
# which is to say, encoding datastructures as bytestrings suitable
# for saving in disk files, sending over network connections,
# or computing message digest hashcodes.
#
# In general, our pickled representation looks a lot like code
# in a portable bytecode instruction.  It consists of opcodes
# identifying what to do (construct a particular kind of value)
# followed by databytes supplying the information needed for
# that particular operation.
#
# For simple types like integer and boolean, pickling reduces to
# just writing an opcode-like typetag byte identifying the type,
# followed by a string of one or more bytes identifying the value.
#
# For a boolean, the typetag is '-9' and the value is "t" or "f".
#
# For an integer, the typetag is '-1' and for the value we use an
# expanding-opcode style encoding in which bit 7 (the high bit)
# gives the sign and bit 6 is a flag indicating whether more data
# bytes follow.  This encodes small integers in a a single byte,
# lets us deal gracefully with word length differences between
# machines, and also cleanly supports indefinite-precision integers.
#
# For a constructor value, the typetag uniquely identifies the
# constructor, a following one-byte discriminator identifies the
# particular constructor of the enum, and the associated
# constructor arguments, if any, follow that.
#
# Our biggest design challenge is to deal properly with sharing,
# which is to say, with multiple pointers to a single value.
# (These could be due to pointer cycles in the datastructure,
# or to shared nodes in a tree package.)
#
# For pure values, handling sharing properly is 'merely' a space
# optimization which in the worst case prevents exponential explosions
# in space consumption during unpickling.
#
# For impure values, handling sharing properly is essential
# to preserving correct semantics: If the unpickler replicates
# stateful chunks, so that changes made to one copy are no longer
# visible in other copies, we will have wild breakage all through
# the code of the unpickled program.
#
# Within the pickle bytestring, sharing is implemented by "back references".
#     Logically, a back reference is a pointer to already-pickled value
# appearing somewhere earlier in the pickle bytestring.
#     Physically, a back reference consists of an all-ones 0xFF byte
# (255 decimal) followed by an integer encoding giving the byte
# offset of the already-pickled value within the pickle bytestring.
# The special 0xFF value is reserved for flagging backreferences.
#
#
#
#                       DATA STRUCTURES
#                       =============== 
#
# Our core pickling datastructre is our 'state' tuple, which contains
# five components:
#
#     backreference map
#     forwarding map
#     ad hoc sharing map
#     pickle length in bytes so far
#     sharing map
#
# The back reference map maintains a mapping between already pickled
# values and their byte address (offset) within the pickle bytestring.
#     Whenever we are about to append a new value to the accumulating
# pickle bytestring, we first check the back reference map to see if
# the value already exists somewhere within the bytestring, and if
# so we simply write a backreference to the pre-existing representation.
#
# The forwarding map ensures that we never encode a backreference to
# a backreference, or something like that, I think... ?
#
# The ad hoc sharing map is actually a parameter to this module
# supplied by the client, which allows additional sharing to be
# implemented above and beyond what the basic sharing algorithm
# would implement.
#
# The "pickle length in bytes so far" value is used to supply the
# offsets entered into (in particular) the backreference map. As
# we will see below, at the time such entries are made, we don't
# have an actual simple pickle string, but rather an abstract
# tree representation whose total length is not easily computed
# by direct means.
#
# Finally, the sharing map tracks all pickled values which are
# referenced by backpointers -- which is to say, all shared
# values.  We flag these values specially for the unpickler. 
# As a result, the unpickler need only keep a table of all
# actually shared values rather than all potentially shared
# values, which saves it a lot of space and a significant
# amount of computation time.
#   On the reasonable assumption that a pickle is read more
# times than it is written, this results in significant overall
# time savings.
#
#
#
#
#                       ALGORITHM
#                       =========
#
# Our pickling algorithm proceeds by three phases.
#
# PHASE 1: Closure-tree construction.
# ----------------------------------
#
# In the first phase, we recursively construct a tree
# of opaque closures.
#     Each closure contains the information for one
# datastructure value or record.
#     Each closure is a function accepting a single argument
# consisting of the above-described state tuple.
#     This representation has the advantage of extreme
# generality, since clients of this modules  can always
# add new kinds of closures to the tree to explicitly encode 
# knowledge about new kinds of datastructures (arrays, say),
# without affecting any of the code in this module.
#     This representation has the corresponding disadvantage
# of being completely opaque:  There is no way to traverse,
# inspect, or update the resulting tree package.  All you
# can do is evaluate it by calling the root closure with a
# state tuple.
#
# PHASE 2: String-tree construction.
# ----------------------------------
#
# Evaluating the phase-one closure tree in this fashion (by
# supplying a state tuple) results in the phase-two representation
# of the pickle, a binary tree consisting entirely of two kinds of
# nodes:
#   STRING nodes containing a bytestring.
#   CONCAT nodes containing two subtrees.
# This representation has advantages and disadvantages inverse
# to those the closure tree:  It is trivial to traverse, inspect
# and modify, but contains no explicit knowledge about different
# datastructure types.
#
# PHASE 3: Flattening the string-tre to a list of strings.
# -----------------------------------------
#
# Our final phase is a linear-time pass over the string tree
# reducing it to a simple list of strings, which are then
# collapsed down into a single final picklestring using the
# standard library 'cat' function.
#     During this phase we also set the 'sharing' bits which
# tell the unpickler which values are actually shared, and
# thus must be entered into its backreference-resolution map.
#
#
#
#
#                       HISTORICAL NOTES
#                       ================
#
# This is the new "generic" pickle utility which replaces Andrew Appel's
# original "sharewrite" module.  Aside from formal differences, this
# new module ended up not being any different from Andrew's.  However,
# it ties in with its "unpickle" counterpart which is a *lot* better than
# its predecessor.
#
# Generated pickles tend to be a little bit smaller, which can
# probably be explained by the slightly more compact (in the common case,
# i.e. for small absolute values) integer representation.
#
# July 1999, Matthias Blume
#
# Addendum: This module now also marks as "actually being shared" those
# nodes where actual sharing has been detected.  Marking is done by
# setting the high bit in the char code of the node.  This means that
# char codes must be in the range [0, 126] to avoid conflicts. (127
# cannot be used because setting the high bit there results in 255 --
# which is the backref code.)
# This improves unpickling time by about 25% and also reduces memory
# usage because much fewer sharing map entries have to be made during
# unpickling.
#
# October 2000, Matthias Blume

# Compiled by:
#     src/lib/compiler/src/library/pickle-lib.make6


#
# By the way, there is no point in trying to internally use
# unt8_vector::Vector instead of string for now.
# These strings participate in order comparisons (which makes
# unt8_vector::Vector unsuitable).  Moreover, conversion between
# string and unt8_vector::Vector is currently just a cast, so it
# does not cost anything in the end.

api Pickle_Utilities {

    Id;

    #  Type info.  Use a different number for each type constructor. 
    #
    Datatype_Tag = Int;			#  negative numbers are reserved! 

    Pickle A_ad_hoc_map;
    Pickler (A_ad_hoc_map, V)   =   V -> Pickle( A_ad_hoc_map );

    # @@@ produces the pickle for one case (constructor) of a enum.
    # The string must be one character long and the argument pickle
    # should be the pickle for the constructor's arguments.
    # Use the same datatype_tag for all constructors of the same enum
    # and different datatype_tags for constructors of different types.
    #
    # The latter is really only important if there are constructors
    # of different type who have identical argument types and use the
    # same @@@ identificaton string.  In this case the pickler might
    # identify two values of different types, and as a result the
    # unpickler will be very unhappy.
    #
    # On the other hand, if you use different datatype_tags for the same type,
    # then nothing terrible will happen.  You might lose some sharing,
    # though.
    #
    # The string argument could theoretically be more than one character
    # long.  In this case the corresponding unpickling function must
    # be sure to get all those characters out of the input stream.
    # We actually do exploit this "feature" internally.
    #
    @@@ : Datatype_Tag -> (String, List( Pickle( A_ad_hoc_map ) )) -> Pickle( A_ad_hoc_map );

    # "ad_hoc_share" is used to specify potential for "ad-hoc" sharing
    # using the user-supplied map.
    # Ad-hoc sharing is used to identify parts of the value that the
    # hash-conser cannot automatically identify but which should be
    # identified nevertheless, or to identify those parts that would be
    # too expensive to be left to the hash-conser.
    #
    ad_hoc_share:   { find:    (A_ad_hoc_map, V) -> Null_Or( Id ),
		      insert:  (A_ad_hoc_map, V, Id) -> A_ad_hoc_map
		    }
		  -> Pickler (A_ad_hoc_map, V)
		  -> Pickler (A_ad_hoc_map, V);

    # Generating pickles for values of some basic types:
    #
    pickle_bool:    Pickler (A_ad_hoc_map, Bool);        
    pickle_int:     Pickler (A_ad_hoc_map, Int);         
    pickle_word:    Pickler (A_ad_hoc_map, Unt);        
    pickle_int32:   Pickler (A_ad_hoc_map, int32::Int);  
    pickle_unt32:  Pickler (A_ad_hoc_map, unt32::Unt); 
    pickle_string:  Pickler (A_ad_hoc_map, String);      

    # Generating pickles for some parameterized types
    # (given a pickler for the parameter):
    pickle_list:    Pickler (A_ad_hoc_map, X)  ->  Pickler (A_ad_hoc_map, List( X ) );
    pickle_option:  Pickler (A_ad_hoc_map, X)  ->  Pickler (A_ad_hoc_map, Null_Or( X ) );
    pickle_pair:   (Pickler (A_ad_hoc_map, X),     Pickler (A_ad_hoc_map, Y)) -> Pickler (A_ad_hoc_map, (X, Y));

    # Pickling a "lazy" value (i.e., a thunk);  the thunk will be forced
    # by the pickler. Unpickling is lazy again; but, of course, that
    # laziness is unrelated to the laziness of the original value.
     pickle_lazy:  Pickler (A_ad_hoc_map, X) ->  Pickler (A_ad_hoc_map, Void -> X);

    #  Run the pickle, i.e., turn it into a String 
     pickle:  A_ad_hoc_map -> Pickle( A_ad_hoc_map ) -> String;

    # The xxx_lifter stuff is here to allow picklers to be "patched
    # together".  If you already have a pickler that uses a sharing map
    # of type B and you want to use it as part of a bigger pickler that
    # uses a sharing map of type A, you must write a (B, A) map_lifter
    # which then lets you lift the existing pickler to one that uses
    # type A maps instead of its own type B maps.
    #
    # The idea is that B maps are really part of A maps. They can be
    # extracted for the duration of using the existing pickler.  Then,
    # when that pickler is done, we can patch the resulting new B map
    # back into the original A map to obtain a new A map.

     Map_Lifter (B_ad_hoc_map, A_ad_hoc_map)
         =
	 {   extract: A_ad_hoc_map -> B_ad_hoc_map,
             patchback: (A_ad_hoc_map, B_ad_hoc_map) -> A_ad_hoc_map
         };

     lift_pickler: Map_Lifter (B_ad_hoc_map, A_ad_hoc_map)
                   -> Pickler (B_ad_hoc_map, V)
                   -> Pickler (A_ad_hoc_map, V);
};

package pickle_utilities:  Pickle_Utilities {		# Pickle_Utilities	is from   src/lib/compiler/src/library/pickle-utilities.pkg

     Pickle_Offset = Int;
     Id            = Pickle_Offset;
     Codes         = List( Id );

     Datatype_Tag = Int;

     Shared_Value_Offsets  = int_red_black_set::Set;

    shared_value_offsets_empty = int_red_black_set::empty;
    shared_value_offsets_add   = int_red_black_set::add;
    shared_value_offsets_list  = int_red_black_set::vals_list;

    package backref_map
        =
        red_black_map_g
	    (
		# Our backref map keys consist of a triple containing the
		# three data needed to uniquely identify one node/value in
		# the datastructure being pickled, namely:
		# o  A string holding the pickled value/contents of the node proper.
		# o  A typetag distinguishing, for example, the string "t" from
		#    the boolean value "t".
		# o  A list of offsets within the pickle of the pickled children
		#    of the node.
		# In other words, for purposes of our base pickling algorithm,
		# two nodes are identical if they have the same type, the same
		# immediate values, and the same child nodes.

		 Key = (String, Datatype_Tag, Codes);

		# Define an ordering over the above Key type.
		# The only purpose of this is to allow us to store
		# and retrieve keys from a binary tree, so the
		# particular ordering relation implemented is noncritical:

		fun compare ((contents, typetag, kidlist), (contents', typetag', kidlist'))
		    =
		    {   fun codes_cmp (    [], []) => EQUAL;
			    codes_cmp (_ ! _, [])  => GREATER;
			    codes_cmp ([], _ ! _)  => LESS;

			    codes_cmp (h ! t, h' ! t')
                                =>
                                if   (h < h')   LESS;
			        elif (h > h')   GREATER;
				else            codes_cmp (t, t');
                                fi;
                        end;

			if   (typetag < typetag')   LESS;
			elif (typetag > typetag')   GREATER;
		        else
						    case (string::compare (contents, contents'))
							 EQUAL   =>  codes_cmp (kidlist, kidlist');
							 unequal =>  unequal;
						    esac;
                        fi;
		    };
	    );

    package forwarding_map
	=
	int_red_black_map;	# int_red_black_map	is from   src/lib/src/int-red-black-map.pkg

    # The string_tree type provides a convenient
    # intermediate pickle representation while we are
    # assembling a pickle.
    # When we're done inserting, deleting and
    # appending, we can flatten a string_tree
    # to an actual pickle string in linear
    # time:
    #
    String_Tree = STRING  String
                         | CONCAT  (String_Tree, String_Tree);
    #
    fun stringtree_size (STRING s) => size s;
        stringtree_size (CONCAT (p, p')) => stringtree_size p + stringtree_size p';
    end;

    # Within the pickle string, the appearance of a 0xFF (255)
    # value signals that the following value is a backreference
    # rather than a literal.  The value 255 is hardwired into
    # the decode/encode logic in various ways, so don't try
    # changing it unless you know exactly what you're doing:

    backref_escape_string = STRING "\255";

    backref_size = 1;              #  Size in bytes of backrefEscapeString. 
    nullbytes = STRING "";

    Backref_Map         = backref_map::Map(     Id );
    Forwarding_Map      = forwarding_map::Map(  Id );
    State( A_ad_hoc_map )  = (Backref_Map, Forwarding_Map, A_ad_hoc_map, Pickle_Offset, Shared_Value_Offsets);

    Pickle( A_ad_hoc_map ) =  State( A_ad_hoc_map ) -> (Codes, String_Tree, State( A_ad_hoc_map ));

    Pickler (A_ad_hoc_map, V) = V -> Pickle( A_ad_hoc_map );

    infix  val 40   @@@ ;
    infixr val 50   &   ;

    # When partially applied, '&' combines a pair of closuretree
    # nodes/subtrees into a single new closuretree node.
    #
    # As with all closuretree nodes, when our partially applied
    # result is then applied to a 'state' tuple, it converts
    # itself into stringtree form.

    fun (closure_tree_node_f & closure_tree_node_g) state
        =
        {   my (shared_value_offsets_list_f, stringtree_f, state' ) = closure_tree_node_f state;
	    my (shared_value_offsets_list_g, stringtree_g, state'') = closure_tree_node_g state';
	
	    (   shared_value_offsets_list_f @ shared_value_offsets_list_g,
                CONCAT (stringtree_f, stringtree_g),
                state''
            );
	};

    # Combine a list of closuretree nodes/subtrees into a
    # single new closuretree.  Our result may be applied
    # to a 'state' tuple to convert it into 'stringtree'
    # form:
    #
    fun combine_closuretree_list (h, []) => h;
        combine_closuretree_list (h, ht ! tt) => h & combine_closuretree_list (ht, tt);
    end;

    fun encode_any_int (n, negative)
        =
        {   # This is essentially the same mechanism used in
	    # oh7-file.pkg --maybe we should share it:
            #
	    /// =  large_unt::(/);
	    %%  =  large_unt::(%);
	    !!  =  large_unt::bitwise_or;
	    #
	    infix val  /// %% !! ;

	    to_w8 = unt8::from_large_unt;

	    fun r (0u0, l) =>  unt8_vector::from_list l;
	        r (  n, l) =>  r (n /// 0u128, to_w8 ((n %% 0u128) !! 0u128) ! l);
            end;

	    last_digit = n %% 0u64;
	    last_byte = if negative  last_digit !! 0u64; else last_digit;fi;
	
	    byte::bytes_to_string (r (n /// 0u64, [to_w8 last_byte]));
	};

    fun encode_large_unt n
        =
        encode_any_int (n, FALSE);

    fun encode_large_int i
        =
	if   (i >= 0) 
             encode_any_int (      large_unt::from_large_int i, FALSE);
	else encode_any_int (0u0 - large_unt::from_large_int i, TRUE );		# Negate in the unsigned domain. 
	fi;

    encode_word32 = encode_large_unt o unt32::to_large_unt;
    encode_word   = encode_large_unt o unt::to_large_unt;

    encode_int32 = encode_large_int o int32::to_large;
    encode_int   = encode_large_int o int::to_large;

    # '%%%' is a helper function which constructs closuretree nodes
    # for input datastructure nodes lacking children.
    #
    # Curried application of %%% to its first two
    # arguments produces the closuretree node.
    #
    # As with all closuretree nodes, application to a 'state' value
    # then serves to compute a stringtree node.
    #
    # The closure we generate will enter the given c+typeTag
    # value pair into the backreference map unless it is already
    # there, in which case it will instead enter into the forwarding
    # table a pointer from its pickle-offset to the backref's
    # pickle-offset.
    # 
    # This fn accepts a three-element input argument containing:
    # 
    # o   typeTag: -1 for integer ... -9 for booleans &tc.  Note that
    #     this doesn't get written to the pickle:  The information is
    #     implicit in the type graph and the de/pickling routines.  It
    #     mainly serves to keep our backref table from confusing, say,
    #     the string value "f" with the boolean value "f".
    #
    # o   'c': discriminator within the type. For example for booleans, it will be "t" or "f".
    #
    # o   Third argument is our standard pickling 'state' value.
    # 
    # The return value consists of a triple containing:
    #  o  A backref offset for the backref list.
    #  o  A 'STRING c' node for the stringtree.
    #  o  Our updated 'state' tuple.
    #
    fun %%% type_tag c (backref_map, forwarding_map, ad_hoc_map, byte_offset_in_pickle, shared_value_offsets)
        =
        {   key = (c, type_tag, []);
	
	    case (backref_map::get (backref_map, key))
	      
	         THE backref_byte_offset_in_pickle
		     =>
		     (   [ backref_byte_offset_in_pickle ],
			 STRING c,
			 (   backref_map,
			     forwarding_map::set (forwarding_map, byte_offset_in_pickle, backref_byte_offset_in_pickle),
			     ad_hoc_map,
			     byte_offset_in_pickle + size c,
			     shared_value_offsets
			 )
		     );

	        NULL
		    =>
		    (    [ byte_offset_in_pickle ],
			 STRING c,
			 (    backref_map::set (backref_map, key, byte_offset_in_pickle),
			      forwarding_map,
			      ad_hoc_map,
			      byte_offset_in_pickle + size c,
			      shared_value_offsets
			 )
		    );
	    esac;
	};


    # When partially applied, 'dollar' creates closuretree
    # nodes.  When these nodes are in turn applied to
    # our usual 'state' tuple argument, they evaluate to
    # stringtree nodes.
    #
    # Arguments are:
    #
    # o  typeTag:  An integer identifying the type of node.
    #
    # o  (c, [childClosuretreeNodes])
    #                              This pair contains the actual useful information
    #                              content of the node. The 'c' string encodes the
    #                              information content of the node proper. The
    #                              the [childClosuretreeNodes] list has one entry
    #                              for each child node.
    #
    # o  'state' tuple.  This gets applied only later,
    #    during conversion from closturetree to stringtree
    #    form.
    #
    fun dollar type_tag (c, []) state
	    =>
	    %%% type_tag c state;

        dollar type_tag (c, firstkid ! morekids) (backref_map, forwarding_map, ad_hoc_map, byte_offset_in_pickle, shared_value_offsets)
	    =>
	    {   closure_tree = combine_closuretree_list (firstkid, morekids);

		my (kidoffsets, stringtree, (backref_map', forwarding_map', ad_hoc_map', byte_offset_in_pickle',         shared_value_offsets'))
		    =
		    closure_tree         (backref_map,  forwarding_map,  ad_hoc_map,  byte_offset_in_pickle + size c, shared_value_offsets);

		key = (c, type_tag, kidoffsets);

		case (backref_map::get (backref_map, key))
		  
		     THE offset => {
					back_ref_num = encode_int offset;

					(   [offset],
					    CONCAT (backref_escape_string, STRING back_ref_num),
					    (   backref_map,
						forwarding_map::set (forwarding_map, byte_offset_in_pickle, offset),
						ad_hoc_map,
						byte_offset_in_pickle + backref_size + size back_ref_num,
						shared_value_offsets_add (shared_value_offsets', offset)
					    )
					);
				    };

		     NULL =>	       (   [byte_offset_in_pickle],
				       CONCAT (STRING c, stringtree),
				       (   backref_map::set (backref_map', key, byte_offset_in_pickle),
					   forwarding_map',
					   ad_hoc_map',
					   byte_offset_in_pickle',
					   shared_value_offsets'
				       )
				   );
		esac;
	    };
    end;

    fun ad_hoc_share { find, insert } w v (backref_map, forwarding_map, ad_hoc_map, byte_offset_in_pickle, shared_value_offsets)
        =
	case (find (ad_hoc_map, v))
	  
	     NULL => w v (backref_map, forwarding_map, insert (ad_hoc_map, v, byte_offset_in_pickle), byte_offset_in_pickle, shared_value_offsets);

	     THE i0 => {     backref_offset = the_else (forwarding_map::get (forwarding_map, i0), i0);
			     back_ref_num   = encode_int backref_offset;

			     (   [backref_offset],
				 CONCAT (backref_escape_string, STRING back_ref_num),
				 (   backref_map,
				     forwarding_map,
				     ad_hoc_map,
				     byte_offset_in_pickle + backref_size + size back_ref_num,
				     shared_value_offsets_add (shared_value_offsets, backref_offset)
				 )
			     );
			 };
	esac;


    fun pickle_lazy w thunk (backref_map, forwarding_map, ad_hoc_map, byte_offset_in_pickle, shared_value_offsets)
        =
        {   v = thunk ();

	    # The larger the value of trialStart, the smaller the chance that
	    # the loop (see below) will run more than once.  However, some
	    # space may be wasted.  3 should avoid this most of the time.
	    # (Experience shows: 2 doesn't.)
	    #
	    trial_start = 3;

	    # This loop is ugly, but we don't expect it to run very often.
	    # It is needed because we must first pickle the length of the
	    # encoding of the thunk's value, but that encoding depends
	    # on the length (or rather: on the length of the length).
	    #
	    fun loop (nxt, ilen)
                =
                {   my (kidoffsets, stringtree, state)
                        =
                        w v (backref_map, forwarding_map, ad_hoc_map, nxt, shared_value_offsets);

		    size' = stringtree_size stringtree;
		    ie = encode_int size';
		    iesz = size ie;

		    # Padding in front is better because the unpickler can
		    # simply discard all leading 0s and does not need to know
		    # about the pickler's setting of "trialStart".
		    #
		    null = STRING "\000";
		    fun pad (stringtree, n)
			=
			if   (n == 0)
			     stringtree;
			else pad (CONCAT (null, stringtree), n - 1);fi;
		
		    if   (ilen < iesz)
		         loop (nxt + 1, ilen + 1);
		    else (kidoffsets, CONCAT (pad (STRING ie, ilen - iesz), stringtree), state);fi;
		};
	
	    loop (byte_offset_in_pickle + trial_start, trial_start);
	};

    stipulate
	iii   = -1;
	www   = -2;
	iii32 = -3;
	www32 = -4;
    herein
	# Note that even though the encoding could start with the
	# backrefEScapeCode character (0xFF), we know that it isn't
	# actually a backref because %%% suppresses back-references.
	# Of course, this must be taken care of by unpickle-util!
	fun pickle_int    i     =   %%% iii   (encode_int    i  );
	fun pickle_word   w     =   %%% www   (encode_word   w  );
	fun pickle_int32  i32   =   %%% iii32 (encode_int32  i32);
	fun pickle_unt32 w32   =   %%% www32 (encode_word32 w32);
    end;

    stipulate

	lll = -5;

	fun chop5 l
	    =
	    ch (reverse l, [])
            where
		fun ch (a ! b ! c ! d ! e ! r, cl)
			=>
			ch (r, (e, d, c, b, a) ! cl);

		    ch (r, cl)
                        =>
                        (reverse r, cl);
                end;

	    end;
    herein
	fun pickle_list w l
	    =
	    {   my (@@@) = dollar lll;

		fun wc []
                        =>
                        %%% lll "N";

		    wc ((a, b, c, d, e) ! r)
                        =>
		        "C" @@@ [w a, w b, w c, w d, w e, wc r];
                end;

		case (chop5 l)
		  
		     ([],           []) => %%% lll "0";
		     ([a],          []) => "1" @@@ [w a];
		     ([a, b],       []) => "2" @@@ [w a, w b];
		     ([a, b, c],    []) => "3" @@@ [w a, w b, w c];
		     ([a, b, c, d], []) => "4" @@@ [w a, w b, w c, w d];

		     ([],            r) => "5" @@@ [wc r];
		     ([a],           r) => "6" @@@ [w a, wc r];
		     ([a, b],        r) => "7" @@@ [w a, w b, wc r];
		     ([a, b, c],     r) => "8" @@@ [w a, w b, w c, wc r];
		     ([a, b, c, d],  r) => "9" @@@ [w a, w b, w c, w d, wc r];
		     _ => raise exception FAIL "pickle_utilities::pickle_list: impossible chop";
                esac;
	    };
    end;

    stipulate
	ooo = -6;
    herein
	fun pickle_option arg
            =
            {   my (@@@) = dollar ooo;

		fun wo w NULL    =>  %%% ooo "n";
		    wo w (THE i) =>  "s" @@@ [w i];
                end;
	    
		wo arg;
	    };
    end;

    stipulate
	ppp = -7;
    herein
	fun pickle_pair (wa, wb) (a, b)
            =
            {   my (@@@) = dollar ppp;
	    
		"p" @@@ [wa a, wb b];
	    };
    end;

    stipulate
	sss = -8;
    herein
	fun pickle_string s
            =
            {   my (@@@) = dollar sss;

		# The dummy_pickle is a hack to get strings to be identified
		# automatically. They don't have "natural" children, so normally
		# %%% would suppress the backref.  The dummy pickle produces no
		# codes and no output, but it is there to make @@@ believe that
		# there are children.
		#
		fun dummy_pickle state
                    =
                    ([], nullbytes, state);

		fun esc '\\'   =>  "\\\\";
		    esc '"'    =>  "\\\"";
		    esc '\255' =>  "\\\255";		# Must escape backref char.
		    esc c      =>  string::from_char c;
                end;
	    
		(cat ["\"", string::translate esc s, "\""]) @@@ [dummy_pickle];
	    };
    end;

    stipulate
	bbb = -9;
    herein
	fun pickle_bool TRUE  => %%% bbb "t";
	    pickle_bool FALSE => %%% bbb "f";
        end;
    end;

    stipulate

	fun stringtree_to_string (
                stringtree,
                pickle_length_in_bytes,
                shared_value_offsets
            )
            =
            {   # 'add' is a utility routine for 'flatten' (see below)
                # which prepends a string to our accumulating result
                # list of strings.
                # 
		# This would be completely trivial except that we must
		# also set the high bit in the first byte of the string
		# if it corresponds to a shared value, as a signal to
                # the unpickler to save this value in its backreference
                # table.
                # 
                # To make this possible, we are given a sorted list of
                # byte offsets within the pickle corresponding to shared
                # values.
                # 
                # We also maintain a 'byteOffsetWithinPickle' state variable
                # giving our current offset within the pickle, which decreases
                # monotonically because we are building up the pickle
                # stringlist back-to-front.
                # 
                # So if our 'byteOffsetWithinPickle' state variable is equal
                # to the top entry on our sharedValueOffsets list, we are at
                # a shared value and must set its high bit.  
		#
		fun add ("",     byte_offset_within_pickle, shared_value_offset, more_shared_value_offsets, stringlist)
			=>
		       (byte_offset_within_pickle, shared_value_offset ! more_shared_value_offsets, stringlist);

		    add (string, byte_offset_within_pickle, shared_value_offset, more_shared_value_offsets, stringlist)
			=>
			{
			    string_length = size string;
			    new_byte_offset_within_pickle = byte_offset_within_pickle - string_length;

			    # If this string is shared (that is, if there
			    # is a backreference to it somewhere) then we
			    # flag this fact for the benefit of the unpickler
			    # by setting the high bit in the first byte of
			    # the string.
			    #   
			    # Otherwise, we can just add it to our result
			    # stringlist as is:

			    if (new_byte_offset_within_pickle == shared_value_offset)	#  Is this a shared string?    
			                                                        	#  Yes.                        
				  new_first_byte			            	#  Set high bit in first byte. 
                                      =
                                      string::from_char
					    (char::from_int
						(char::to_int (string::get (string, 0)) + 128));

				  fun ret stringlist
                                      =
                                      (new_byte_offset_within_pickle, more_shared_value_offsets, stringlist);

				  # If it is a one-byte string we can just prepend our
				  # just-computed high byte to result stringlist,
				  # otherwise we need to prepend both first-byte
				  # and rest-of-string:
				  #
				  if   (string_length > 1)
				       ret (new_first_byte ! string::extract (string, 1, NULL) ! stringlist);
				  else ret (new_first_byte ! stringlist);fi;


			    else
                                   (new_byte_offset_within_pickle, shared_value_offset ! more_shared_value_offsets, string ! stringlist);
                            fi;

			};
                end;

		# fast_flatten is a faster, simpler version of 'flatten'
                # (see below) which we switch to once we are out of
                # shared codes:
		#
		fun fast_flatten (STRING string, stringlist)
                        =>
                        string ! stringlist;

		    fast_flatten (CONCAT (stringtree, STRING string), stringlist)
		        =>
		        fast_flatten (stringtree, string ! stringlist);

		    fast_flatten (CONCAT (stringtree_a, CONCAT (stringtree_b, stringtree_c)), stringlist)
			=>
			fast_flatten (CONCAT (CONCAT (stringtree_a, stringtree_b), stringtree_c), stringlist);
                end;

		# 'flatten' converts a stringtree into a list of
                # strings in one linear-time pass, which stringlist
                # is then 'cat'-ed to produce the final pickle
                # string.
                #
                # We build up the stringlist back-to-front since it
                # is easier to prepend values to a list than to append
                # them.
                #
		# During this pass, we also set the high bits in
		# those bytecodes that correspond to shared nodes.
                # The positions of these codes are given by our
                # sharedCodes argument, which is a high-to-low
		# sorted list of integers.
                # First argument is the stringtree to flatten.
                # Second argument is a triple consisting of:
                #    byteOffsetWithinPickle:    Monotonically decreasing intra-pickle address.
                #    sharedValueOffsets: List of offsets within the pickle which
                #                 correspond to shared values (== values
                #                 with backreferences).  We pass this info
                #                 on to the unpickler via high-bit flags;
                #                 This allows the unpickler to avoid entering
                #                 into its backreference table values which
                #                 do not have any backreferences.
                #    stringlist:  The accumulating result list of strings
                #                 which together constitute the result pickle.
		#
		fun flatten (stringtree, (_, [], stringlist))               => fast_flatten (stringtree, stringlist);

		    flatten (STRING string, (byte_offset_within_pickle, shared_value_offset ! more_shared_value_offsets, stringlist))
			=>
			#3 (add (string, byte_offset_within_pickle, shared_value_offset, more_shared_value_offsets, stringlist));

		    flatten (CONCAT (stringtree, STRING string), (byte_offset_within_pickle, shared_value_offset ! more_shared_value_offsets, stringlist))
			=>
			flatten (stringtree, add (string, byte_offset_within_pickle, shared_value_offset, more_shared_value_offsets, stringlist));

		    flatten (CONCAT (stringtree_a, CONCAT (stringtree_b, stringtree_c)), arg_triple)
			=>
			flatten (CONCAT (CONCAT (stringtree_a, stringtree_b), stringtree_c), arg_triple);
                end;

                # Flatten the stringtree into a list of strings,
                # and then concatenate that list to produce the
                # final pickle string:

		cat (flatten (stringtree, (pickle_length_in_bytes, reverse (shared_value_offsets_list shared_value_offsets), [])));
	    };
    herein
        # Convert a closureTree into a stringTree and thence
        # to a single string -- the result pickle:

	fun pickle ad_hoc_map closure_tree
            =
            {   my (_, stringtree, (_, _, _, pickle_length, shared_value_offsets))
		    =
		    closure_tree (backref_map::empty, forwarding_map::empty, ad_hoc_map, 0, shared_value_offsets_empty);
	    
		stringtree_to_string (stringtree, pickle_length, shared_value_offsets);
	    };
    end;





     Map_Lifter (B_ad_hoc_map, A_ad_hoc_map)
         =
         {   extract:    A_ad_hoc_map                 -> B_ad_hoc_map,
             patchback: (A_ad_hoc_map, B_ad_hoc_map) -> A_ad_hoc_map
         };

    fun lift_pickler { extract, patchback } wb b (backref_map, forwarding_map, a_ad_hoc_map, byte_offset_in_pickle, shared_value_offsets)
        =
	{   b_ad_hoc_map =   extract a_ad_hoc_map;

	    my (kidoffsets, stringtree, (backref_map', forwarding_map', b_ad_hoc_map', byte_offset_in_pickle', shared_value_offsets'))
                =
		wb b (backref_map, forwarding_map, b_ad_hoc_map, byte_offset_in_pickle, shared_value_offsets);

	    a_ad_hoc_map' =   patchback (a_ad_hoc_map, b_ad_hoc_map');
	
	    (kidoffsets, stringtree, (backref_map', forwarding_map', a_ad_hoc_map', byte_offset_in_pickle', shared_value_offsets'));
	};

    # For export:
    #
    nonfix val  @@@;
    @@@ = dollar;
};


##########################################################################
#   The following is support for outline-minor-mode in emacs.		 #
#  ^C @ ^T hides all Text. (Leaves all headings.)			 #
#  ^C @ ^A shows All of file.						 #
#  ^C @ ^Q Quickfolds entire file. (Leaves only top-level headings.)	 #
#  ^C @ ^I shows Immediate children of node.				 #
#  ^C @ ^S Shows all of a node.						 #
#  ^C @ ^D hiDes all of a node.						 #
#  ^HFoutline-mode gives more details.					 #
#  (Or do ^HI and read emacs:outline mode.)				 #
#									 #
# Local variables:							 #
# mode: outline-minor							 #
# outline-regexp: "[{ \t]*\\(fun \\)"			 		 #
# End:									 #
##########################################################################
